================================================================================
AUTONOMY ARCHITECTURE MANIFESTO
The Three-Layer System for True Autonomous Agents
================================================================================

Source Document Type: Research Commentary
Date: [Original Research]
Attribution: Based on cognitive robotics research and humanoid robotics experience
Context: This manifesto explains why LLMs alone cannot produce truly autonomous systems,
         and what architecture is actually required.

================================================================================

PREMISE: LLMs ALONE ARE INSUFFICIENT

Large language models alone will never produce a fully autonomous system.

Anyone who has tried to make a robot operate reliably already understands that.

The missing pieces aren't mysterious.

They've been mapped out for years in cognitive robotics, even if some of the
required components are still beyond current capabilities.

================================================================================

THE THREE-LAYER ARCHITECTURE FOR AUTONOMY

From my experience in humanoid robotics, the following architecture captures what
a genuinely autonomous agent actually needs:

================================================================================

LAYER 1: HIGH-FREQUENCY PERCEPTION AND ACTION LOOP
(The Bottom Layer - Raw Sensorimotor Control)

The high-frequency perception and action loop at the bottom handles raw sensory
input, motor commands, and tight real-time constraints.

Key Characteristics:
  • Reacts quickly to sensory input
  • Keeps the system stable
  • Operates at highest frequency (most responsive)
  • Lowest latency tolerance
  • Minimal computational overhead

Responsibilities:
  • Capture raw sensory data (vision, proprioception, etc.)
  • Issue motor commands for immediate response
  • Handle tight real-time constraints (milliseconds)
  • Implement reflexes and safety constraints
  • Maintain system stability during perturbations

Technologies:
  • Signal processing for sensor fusion
  • Control theory (PID, impedance control)
  • Real-time kernels
  • Parallel processing for simultaneous perception/action

In Software Development Context (CODITECT):
  • Layer 3: Worker Agents (Perception/Action)
  • Continuous execution without waiting for central planning
  • Fast local decisions (code execution, test running)
  • Immediate response to anomalies

================================================================================

LAYER 2: SITUATION ASSESSMENT & WORLD MODELING
(The Middle Layer - State Management & Anomaly Detection)

The situation assessment layer sits in the middle. It maintains a world model,
updates internal state, detects inconsistencies by comparing the world model
prediction with the reality, and triggers exploration when reality contradicts
expectations.

This is the bridge between reflexive behavior and deliberate cognition.

Key Characteristics:
  • Medium frequency (100-500ms cycles)
  • Medium computational cost
  • Reactive to anomalies
  • Maintains coherent state representation
  • Detects prediction failures

Core Components:

1. WORLD MODEL
   Maintains internal representation of:
   • Current state of all components
   • Known constraints and relationships
   • Recent history of changes
   • Expected future states (predictions)

2. INCONSISTENCY DETECTION
   Compares:
   • Predicted state (what we expect to happen)
   • Actual state (what really happened)

   When mismatch detected:
   • Flags anomaly
   • Triggers investigation
   • Updates world model understanding
   • Learns from discrepancy

3. STATE SYNCHRONIZATION
   Keeps all components aware of:
   • Current system status
   • Known constraints
   • Recent decisions and outcomes
   • Anomalies that have occurred

Responsibilities:
  • Monitor real-time sensory updates from Layer 1
  • Maintain accurate world model
  • Predict expected outcomes of actions
  • Detect when expectations don't match reality
  • Trigger problem-solving when consistency violated
  • Provide context to Layer 3 for action selection
  • Report status to Layer 1 for stability control

Why This Is Essential:
  • Blind execution is dangerous (no anomaly detection)
  • Reactive retry is expensive (no learning)
  • Silent failures are worst case (system degradation)
  • Autonomy requires knowing when something went wrong
  • True learning requires understanding mismatches

The PhD Work:
  Situation assessment and world modeling were the focus of my PhD research.
  This layer is the hardest to get right, but it's the critical differentiator
  between reflexive systems and truly autonomous systems.

In Software Development Context (CODITECT):
  • Layer 2: Task Queue Manager
  • World model: Current state of all files, tests, agents
  • Consistency detection: Expected test pass → actual test fail = investigate
  • Enables autonomous error recovery (99%+ success without human)

================================================================================

LAYER 3: DELIBERATIVE PLANNING & SUPERVISION
(The Top Layer - Goal Formation & High-Level Reasoning)

The top deliberative layer manages intent, supervises behavior, and performs
high-level planning. This is where goals are formed, simulations run, and
abstract intentions turn into concrete actions that cascade downwards.

Key Characteristics:
  • Lowest frequency (slowest, most expensive)
  • Highest computational cost (complex reasoning)
  • Most flexible and adaptive
  • Works at abstract/symbolic level
  • Responsible for long-term coherence

Responsibilities:
  • Interpret high-level goals and intent
  • Perform abstract planning and simulation
  • Decompose goals into sub-goals
  • Supervise overall system behavior
  • Adapt strategy based on feedback
  • Manage resource allocation
  • Handle novel situations
  • Learn from patterns across many episodes

In Software Development Context (CODITECT):
  • Layer 1: Orchestrator
  • LLM-based planning (Claude 3.5 Sonnet)
  • Goal decomposition (Analyze → Code → Test)
  • Supervision (tracking milestones)
  • Strategic decision-making (every 10 minutes)

================================================================================

THE LAYERED SYSTEM IN ACTION

Each Layer Operates at Its Own Timescale:

Layer 1 (Perception/Action):  Frequency 1ms or faster
Layer 2 (Situation):          Frequency 100-500ms
Layer 3 (Deliberation):       Frequency 1-10 minutes

Why Different Timescales?

Speed vs. Cost Tradeoff:
  • Layer 1: Must be fast (stability and safety) → simple computations
  • Layer 2: Medium speed (situational awareness) → moderate complexity
  • Layer 3: Can be slow (planning) → unlimited complexity

Example Workflow:
  1. Layer 1: "Motor feedback indicates we're slipping"
  2. Layer 2: "World model predicts grasp will fail"
  3. Layer 2: "Actual sensor data shows slippage"
  4. Layer 2: "Consistency violation detected!"
  5. Layer 2: "Trigger investigation: increase grip force"
  6. Layer 3: "Revise future plan given updated understanding"

Autonomy Emerges from Interaction Between Layers:

The coordination between layers is what creates true autonomy:
  • Reflexes without consciousness (Layer 1 alone): Not autonomous, not intelligent
  • Consciousness without reflexes (Layer 3 alone): Not viable, too slow, brittle
  • Consciousness + reflexes + mediation (all three): Truly autonomous system

No single model (especially not LLM alone) can replace the entire stack.

================================================================================

WHY LARGE LANGUAGE MODELS ALONE FAIL

What LLMs Are Good At:
  ✓ Abstract reasoning and planning
  ✓ Natural language understanding
  ✓ Learning patterns from training data
  ✓ Generating reasonable strategies
  ✓ Contextual adaptation

What LLMs Are Terrible At:
  ✗ Real-time response (millisecond latency)
  ✗ Embodied perception and control
  ✗ Detecting logical contradictions in real-world experience
  ✗ Maintaining accurate persistent state
  ✗ Learning from individual experiences
  ✗ Understanding causality through doing (embodied learning)
  ✗ Operating cost-effectively (expensive per call)

The Fatal Flaw of LLM-Only Systems:

If you call an LLM for every decision:
  • Response time: Too slow (100ms+ latency per call)
  • Cost: Prohibitive (scales with decision frequency)
  • Learning: Doesn't improve from experience
  • Anomaly Detection: None (can only make next prediction, not detect mismatches)
  • Safety: Brittle (no stable reflexive layer)

Result: Not autonomous, not reliable, not scalable.

================================================================================

THE ROLE OF LARGE MODELS IN AUTONOMOUS SYSTEMS

In a future where a single large model plays a bigger role than we expect
(for example it makes sense to use an LLM, but not alone, in the supervision layer),
its functions will differ drastically depending on the layer, and each role will
still need to be managed within a broader neuro-symbolic framework.

Appropriate Use of LLMs:

Layer 1 (Perception/Action): NO
  Why: Too slow, too expensive, can't maintain real-time control

Layer 2 (Situation Assessment): LIMITED
  Possible use: Anomaly analysis, planning next investigation step
  But: Must be combined with symbolic reasoning, consistency checking
  Cost: Selective use only, not every cycle

Layer 3 (Deliberation): YES
  Why: This is where LLMs excel
  Use case: Planning, goal decomposition, abstract reasoning
  But: Must be constrained by consistent feedback from Layer 2

Example LLM Integration in Three-Layer System:

```
Layer 1 (Perception/Action):
  • No LLM calls
  • Pure control algorithms
  • Executes every 1ms

Layer 2 (Situation Assessment):
  • Occasional LLM calls for anomaly investigation
  • LLM analyzes: "Test failed with XError. Why might this happen?"
  • Uses symbolic reasoning for state updates
  • Executes every 100-500ms

Layer 3 (Deliberation):
  • Heavy LLM use for planning
  • LLM generates: "To achieve goal X, we need: A, then B, then C"
  • Uses symbolic reasoning for goal decomposition
  • Executes every 10 minutes
```

The Neuro-Symbolic Framework:

Neural (LLM):                Symbolic (Traditional):
  • Pattern recognition        • Consistency checking
  • Generalization             • Logic enforcement
  • Flexible reasoning         • Constraint satisfaction
  • Natural language           • Formal verification
  • Learning from data         • Explicit state management

Neither alone is sufficient. Together, they create true autonomy.

================================================================================

THE CORE INSIGHT

Real Autonomy Isn't a Monolith, It's a System.

A truly autonomous agent requires:

1. STABLE REFLEXIVE LAYER
   Must: Keep system functioning in adverse conditions
         Respond immediately to dangers
         Maintain embodied control

2. COHERENT STATE LAYER
   Must: Know what's happening in the world
         Detect when predictions fail
         Learn from mismatches
         Enable anomaly-triggered problem-solving

3. DELIBERATE PLANNING LAYER
   Must: Form and supervise high-level goals
         Perform abstract reasoning
         Adapt strategy based on feedback
         Handle novel situations

Each layer needs appropriate tools:
  • Layer 1: Control algorithms, not LLMs
  • Layer 2: Symbolic reasoning + selective LLM, not LLMs alone
  • Layer 3: LLMs + symbolic constraints, not free-form generation

The Interaction Creates Autonomy:

When these three layers interact properly:
  • Layer 1 keeps things stable while Layer 3 thinks
  • Layer 2 detects problems and escalates to Layer 3
  • Layer 3 adapts strategy based on Layer 2 feedback
  • Layer 1 executes Layer 3's strategy robustly

Result: A system that can handle novel situations, adapt strategy, maintain
safety, and improve through experience.

================================================================================

IMPLICATIONS FOR SOFTWARE DEVELOPMENT AUTONOMY

If we apply this to autonomous software development (as with CODITECT):

Layer 1 (Worker Agents):
  • Execute code (write, test, analyze)
  • No expensive LLM calls during execution
  • Pure algorithmic operations
  • Report results + anomalies

Layer 2 (Task Queue Manager):
  • Maintain world model (which files changed, which tests passed)
  • Detect consistency violations (expected test pass, but actually failed)
  • Trigger investigation (analyze why the test failed)
  • Update understanding for next planning cycle

Layer 3 (Orchestrator):
  • Plan: What code should be written, in what order
  • Supervise: Are we on track to complete the goal?
  • Adapt: Does the failing test indicate a strategy change needed?

With this architecture:
  ✓ LLM calls are rare (every 10 minutes, not every second)
  ✓ Cost is manageable (10-50x reduction possible)
  ✓ System improves from experience (learns from failures)
  ✓ Anomalies are detected (can trigger investigation)
  ✓ Autonomy increases (less human intervention needed)

================================================================================

ATTRIBUTION & ACKNOWLEDGMENT

Credit: Yoan Sallami, PhD

This architectural framework is grounded in:
  • Cognitive robotics research
  • Humanoid robotics implementation experience
  • PhD research in situation assessment and world modeling
  • Years of experience making robots operate reliably in real environments

The key insight—that autonomy requires coordinated perception, memory, reasoning,
and action, not just more powerful reasoning—comes from practical experience with
embodied systems where the consequences of failed autonomy are physical failures,
safety issues, and costly hardware damage.

================================================================================

CONCLUSION

True autonomy isn't a monolith. It's a system.

No single model (including large language models) can replace the entire stack
of perception, memory, reasoning, and action.

The three-layer architecture with different timescales and different computational
strategies has been proven to work in robotics. The same principles apply to
autonomous software development.

This is not theoretical speculation. This is practical engineering based on years
of experience building systems that actually had to work.

The diagram showing three layers operating at different frequencies is simplified,
but in my opinion it is the most practical and technically grounded blueprint for
building a truly autonomous agent—whether that agent is a robot or a software
development system.

================================================================================

KEY TAKEAWAYS FOR BUILDERS

1. Don't try to do everything with an LLM
   → Use it only where it's appropriate (planning/reasoning)

2. Build the missing layers
   → Perception/action layer (execution)
   → Situation assessment layer (anomaly detection)

3. Connect them with proper communication
   → Upward: Results and anomalies
   → Downward: Goals and actions
   → Sideways: Consistency violations

4. Optimize for different frequencies
   → Bottom layer: As fast as possible (no LLM)
   → Middle layer: Medium speed (selective LLM use)
   → Top layer: Slow is fine (heavy LLM use okay)

5. Let autonomy emerge from interaction
   → Don't try to put all intelligence in one place
   → Different layers serve different functions
   → The system is smarter than any single component

This is the path to true autonomy. Not more powerful models, but smarter systems.

================================================================================
END OF MANIFESTO
================================================================================
